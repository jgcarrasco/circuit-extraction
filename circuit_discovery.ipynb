{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgcarrasco/.virtualenvs/mech_interp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "import itertools\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "import einops\n",
    "\n",
    "from typing import Literal\n",
    "from jaxtyping import Float\n",
    "\n",
    "from transformer_lens import HookedTransformer, ActivationCache\n",
    "from transformer_lens import utils\n",
    "\n",
    "from easy_transformer.ioi_dataset import IOIDataset\n",
    "from easy_transformer.ioi_utils import logit_diff as ioi_logit_diff\n",
    "\n",
    "from utils import get_data, compute_logit_diff_acronym\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "n_patching = 100\n",
    "n_val = 100\n",
    "task = \"acronyms\"\n",
    "\n",
    "data = get_data(n_patching=n_patching, n_val=n_val, task=task)\n",
    "\n",
    "model = data[\"model\"]\n",
    "\n",
    "patching_tokens = data[\"patching_tokens\"] \n",
    "patching_answer_tokens = data[\"patching_answer_tokens\"] \n",
    "patching_logits = data[\"patching_logits\"] \n",
    "patching_cache = data[\"patching_cache\"]\n",
    "\n",
    "val_tokens = data[\"val_tokens\"] \n",
    "val_answer_tokens = data[\"val_answer_tokens\"]\n",
    "val_logits = data[\"val_logits\"]\n",
    "val_cache = data[\"val_cache\"]\n",
    "\n",
    "gt_circuit = data[\"gt_circuit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(val_logits, val_answer_tokens):\n",
    "    return (val_logits[:, -1].argmax(-1) == val_answer_tokens[:, -1]).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablate_head(activations, hook, head_idx, scheme, new_cache=None):\n",
    "    \"\"\"\n",
    "        Ablates a head from the layer specified by hook and the \n",
    "        index specified by `head_idx`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        - `activations`: output of the hook. \n",
    "        Usually will have shape `(batch, pos, head, d_head)`\n",
    "        - `hook`: This specifies where the hook will be located. Usually will be\n",
    "        of the shape 'blocks.0.attn.hook_result'\n",
    "        - `head_idx`: The index of the head that we want to ablate\n",
    "        - `scheme`: Either \"zero\" or \"mean\" for zero or mean ablation.\n",
    "        - `new_cache`: Cache that will be used when performing mean ablation\n",
    "    \"\"\"\n",
    "    assert scheme in [\"mean\", \"zero\"], \"the ablation scheme should be either 'mean' or 'zero'\"\n",
    "\n",
    "    if scheme == \"mean\":\n",
    "        assert new_cache is not None, \"`new_cache` is required when mean ablating\"\n",
    "        activations[:, :, head_idx] = new_cache[hook.name][:, :, head_idx].mean(0)[None, ...]\n",
    "    elif scheme == \"zero\":\n",
    "        activations[:, :, head_idx] = 0.\n",
    "    return activations\n",
    "\n",
    "def ablate_mlp(activations, hook, scheme, new_cache=None):\n",
    "    assert scheme in [\"mean\", \"zero\"], \"the ablation scheme should be either 'mean' or 'zero'\"\n",
    "\n",
    "    if scheme == \"mean\":\n",
    "        assert new_cache is not None, \"`new_cache` is required when mean ablating\"\n",
    "        activations[:, :, :] = new_cache[hook.name][:, :, :].mean(0)[None, ...]\n",
    "    elif scheme == \"zero\":\n",
    "        activations[:, :, :] = 0.\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_patching(val_tokens, score_func, baseline_scores, model, patching_cache):\n",
    "    model.reset_hooks(including_permanent=True)\n",
    "    corrupted_scores = torch.zeros((model.cfg.n_layers, model.cfg.n_heads))\n",
    "    with torch.no_grad():\n",
    "        for layer, head in tqdm(list(product(range(model.cfg.n_layers), range(model.cfg.n_heads)))):\n",
    "            model.reset_hooks(including_permanent=True)\n",
    "            hook_fn = partial(ablate_head, head_idx=head, scheme=\"mean\", new_cache=patching_cache)\n",
    "            model.add_hook(utils.get_act_name(\"result\", layer), hook_fn)\n",
    "            corrupted_logits = model(val_tokens)\n",
    "            corrupted_score = score_func(corrupted_logits)\n",
    "            corrupted_scores[layer, head] = corrupted_score\n",
    "\n",
    "    attribution_score = (corrupted_scores - baseline_scores.cpu())\n",
    "    return attribution_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KL-divergence algorithm\n",
    "\n",
    "Sort the nodes in reverse topological. Note that we are working with nodes instead of edges. In this case, nodes represent activations (or components) and edges represent computations. As GPUs are very good at performing lots of parallel computations, we will not gain that much speed and/or space. As our objective is to perform a pruning method that leaves us with more interpretable models, we therefore focus on removing nodes. This is also good because there are way less nodes that edges, so that the algorithm will generally be faster.\n",
    "\n",
    "Also, we used the logit difference in the previous experiment, but in ACDC they recommend using the KL divergence as it performs better in most cases. There are cases where a more specific metric is required. However, let's try to use the KL divergence: if we recover the acronym circuit, then keep going.\n",
    "\n",
    "One more thing is that we also have to choose the ablation scheme: zero-ablating might be more aggressive, hence more nodes will be present in the resulting circuit, whereas mean-ablating might be more precise but we require to add a bias term to compensate for removing each component. **This comes with a great setback: the bias vector depends on the length of the sequence, so we either stick to sentences with the same template or think about some other method.**\n",
    "\n",
    "So, a todo list:\n",
    "\n",
    "- ~~Implement the KL-based pruning algorithm (mean and zero).~~\n",
    "- Add MLPs to the algorithm\n",
    "- ~~Check if we obtain results similar to the acronym paper.~~\n",
    "- ~~Experiment with zero/mean ablation~~\n",
    "- Actually obtain a pruned model\n",
    "\n",
    "Cool visualizations\n",
    "- ~~Pareto frontier~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_circuit(threshold, score_func, curr_logits, val_tokens, patching_cache, model, ablation_scheme=\"mean\", include_mlps=False):\n",
    "    model.reset_hooks(including_permanent=True)\n",
    "    circuit = []\n",
    "    circuit_mlps = []\n",
    "\n",
    "    # Traverse the nodes from downstream to upstream\n",
    "    for layer in tqdm(reversed(range(model.cfg.n_layers)), total=model.cfg.n_layers):\n",
    "        for head in range(model.cfg.n_heads):\n",
    "            # temporarily remove node\n",
    "            hook_fn = partial(\n",
    "                ablate_head, head_idx=head, scheme=ablation_scheme, new_cache=patching_cache\n",
    "                )\n",
    "            model.add_hook(utils.get_act_name(\"result\", layer), hook_fn, is_permanent=False)\n",
    "            temp_logits = model(val_tokens).clone()\n",
    "            \n",
    "            if (score_func(temp_logits).mean(0) - score_func(curr_logits).mean(0)) < threshold:\n",
    "                # if the KL divergence does not increase over a threshold, the node\n",
    "                # is not important, so remove permanently\n",
    "                model.add_hook(utils.get_act_name(\"result\", layer), hook_fn, is_permanent=True)\n",
    "                curr_logits = temp_logits.clone()\n",
    "            else:\n",
    "                # include node in the circuit\n",
    "                circuit.append([layer, head])\n",
    "            model.reset_hooks(including_permanent=False)\n",
    "        # repeat for MLP\n",
    "        # temporarily remove node\n",
    "        hook_fn = partial(\n",
    "            ablate_mlp, scheme=ablation_scheme, new_cache=patching_cache\n",
    "            )\n",
    "        model.add_hook(utils.get_act_name(\"result\", layer), hook_fn, is_permanent=False)\n",
    "        temp_logits = model(val_tokens).clone()\n",
    "\n",
    "        if (score_func(temp_logits).mean(0) - score_func(curr_logits).mean(0)) < threshold:\n",
    "            # if the KL divergence does not increase over a threshold, the node\n",
    "            # is not important, so remove permanently\n",
    "            model.add_hook(utils.get_act_name(\"result\", layer), hook_fn, is_permanent=True)\n",
    "            curr_logits = temp_logits.clone()\n",
    "        else:\n",
    "            # include node in the circuit\n",
    "            circuit_mlps.append([layer])\n",
    "        model.reset_hooks(including_permanent=False)\n",
    "            \n",
    "    return circuit, circuit_mlps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_autocircuit(task=\"acronyms\", ablation_scheme=\"mean\", include_mlps=False):\n",
    "\n",
    "    try:\n",
    "        with open(f\"logs/{task}_{ablation_scheme}{'_mlp' if include_mlps else ''}.pkl\", \"rb\") as handle:\n",
    "            log = pickle.load(handle)\n",
    "    except FileNotFoundError:\n",
    "        log = {}\n",
    "    \n",
    "    data = get_data(n_patching=n_patching, n_val=n_val, task=task)\n",
    "\n",
    "    model = data[\"model\"]\n",
    "    patching_cache = data[\"patching_cache\"]\n",
    "\n",
    "    val_tokens = data[\"val_tokens\"] \n",
    "    val_logits = data[\"val_logits\"]\n",
    "\n",
    "    baseline_logprobs = F.log_softmax(val_logits.clone(), dim=-1).clone()\n",
    "    score = partial(kl_div, baseline_logprobs=baseline_logprobs, pos=-1)\n",
    "\n",
    "    thresholds = 10**np.linspace(0, -6, 20)\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        circuit, circuit_mlps = auto_circuit(threshold, score, val_logits.clone(), val_tokens, patching_cache, model, ablation_scheme=ablation_scheme, include_mlps=include_mlps)\n",
    "        log[threshold] = [circuit, circuit_mlps]\n",
    "    \n",
    "    with open(f\"logs/{task}_{ablation_scheme}{'_mlp' if include_mlps else ''}.pkl\", \"wb\") as handle:\n",
    "        pickle.dump(log, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, scheme, include_mlps in product([\"acronyms\", \"ioi\", \"greater-than\"], [\"mean\", \"zero\"], [False, True]):\n",
    "    sweep_autocircuit(task=task, ablation_scheme=scheme, include_mlps=include_mlps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"logs/acronyms_mean.pkl\", \"rb\") as handle:\n",
    "    log = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_frontier(task=\"acronyms\", ablation_scheme=\"mean\"):\n",
    "    \"\"\"\n",
    "    Applies the discovery algorithm with different threshold and gathers the TPRs and FPRs,\n",
    "    comparing the obtained circuit with the ground truth.\n",
    "    \"\"\"\n",
    "\n",
    "    data = get_data(n_patching=n_patching, n_val=n_val, task=task)\n",
    "\n",
    "    model = data[\"model\"]\n",
    "\n",
    "    patching_tokens = data[\"patching_tokens\"] \n",
    "    patching_answer_tokens = data[\"patching_answer_tokens\"] \n",
    "    patching_logits = data[\"patching_logits\"] \n",
    "    patching_cache = data[\"patching_cache\"]\n",
    "\n",
    "    val_tokens = data[\"val_tokens\"] \n",
    "    val_answer_tokens = data[\"val_answer_tokens\"]\n",
    "    val_logits = data[\"val_logits\"]\n",
    "    val_cache = data[\"val_cache\"]\n",
    "\n",
    "    gt_circuit = data[\"gt_circuit\"]\n",
    "\n",
    "    baseline_logprobs = F.log_softmax(val_logits.clone(), dim=-1).clone()\n",
    "    score = partial(kl_div, baseline_logprobs=baseline_logprobs, pos=-1)\n",
    "\n",
    "    thresholds = 10**np.linspace(0, -6, 40)\n",
    "\n",
    "    tprs = []\n",
    "    fprs = []\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        circuit = auto_circuit(threshold, score, val_logits.clone(), val_tokens, patching_cache, model, ablation_scheme=ablation_scheme)\n",
    "        tpr = len([head for head in circuit if head in gt_circuit]) / len(gt_circuit)\n",
    "        fpr = len([head for head in circuit if head not in gt_circuit]) / (144 - len(gt_circuit))\n",
    "        tprs.append(tpr); fprs.append(fpr)\n",
    "    return tprs, fprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pareto_experiment(ablation_scheme):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    markers = [\"o\", \"^\", \"x\"]\n",
    "    for i, task in enumerate([\"acronyms\", \"greater-than\", \"ioi\"]):\n",
    "        tprs, fprs = pareto_frontier(task=task, ablation_scheme=ablation_scheme)\n",
    "        # add the ends for prettier plots\n",
    "        fprs = [0] + fprs + [1]\n",
    "        tprs = [0] + tprs + [1]\n",
    "        try:\n",
    "            auc_score = auc(fprs, tprs)\n",
    "        except:\n",
    "            auc_score = 0.\n",
    "        ax.plot(fprs, tprs, f'-', color=f\"C{i}\", drawstyle='steps-post', label=f\"{task} (AUC: {auc_score:.2f})\")\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mplot_pareto_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mablation_scheme\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m, in \u001b[0;36mplot_pareto_experiment\u001b[0;34m(ablation_scheme)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_pareto_experiment\u001b[39m(ablation_scheme):\n\u001b[0;32m----> 2\u001b[0m     fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m     markers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macronyms\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreater-than\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mioi\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig = plot_pareto_experiment(ablation_scheme=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"pareto-zero.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mech_interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
